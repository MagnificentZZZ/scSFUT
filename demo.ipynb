{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from my_model.mlp_cls import MLP\n",
    "from my_model.trans_enc_cls import  TransformerEncoder\n",
    "from my_model.mydata import mydataSet\n",
    "from my_model.util import setup_seed, count_labels, compute_mean_std\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with cuda\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Train with', device)\n",
    "\n",
    "#128, 16\n",
    "hidden_size_1 = 512\n",
    "hidden_size_2 = 64\n",
    "batch_size = 64\n",
    "num_epochs = 25\n",
    "num_folds = 5\n",
    "learning_rate = 0.0005\n",
    "random_seed = 42\n",
    "dataset_name = 'Baron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_produce(token_dim):\n",
    "\n",
    "    adata = sc.read_h5ad(f\"./cls_data/preprocessed_{dataset_name}.h5ad\")\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "    X = adata.X\n",
    "\n",
    "    y = adata.obs['cell_type']\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    with open('label_encoder_Baron.pkl', 'wb') as file:\n",
    "        pickle.dump(label_encoder, file)\n",
    "\n",
    "\n",
    "    \n",
    "    data = pd.DataFrame(X.toarray() if hasattr(X, 'toarray') else X, columns=adata.var_names)\n",
    "    data[\"label\"] = y_encoded\n",
    "\n",
    "    label_counts = data[\"label\"].value_counts()\n",
    "    print(\"Label Counts:\", label_counts)\n",
    "\n",
    "    embedding_dim = token_dim\n",
    "    features = data.iloc[:, :-1]\n",
    "    num_samples, num_features = features.shape\n",
    "    remaining_features = num_features % embedding_dim\n",
    "\n",
    "    if remaining_features != 0:\n",
    "        padding_size = embedding_dim - remaining_features\n",
    "        features_padded = pd.concat([features, pd.DataFrame(np.zeros((num_samples, padding_size)))], axis=1)\n",
    "    else:\n",
    "        features_padded = features\n",
    "\n",
    "    # Calculate the number of tokens\n",
    "    num_tokens = features_padded.shape[1] // embedding_dim\n",
    "\n",
    "    # Create a 3D array to store data\n",
    "    grouped_features = np.zeros((num_samples, num_tokens, embedding_dim))\n",
    "\n",
    "    # Fill the array with token vectors\n",
    "    for i in range(num_tokens):  \n",
    "\n",
    "        start_idx = i * embedding_dim\n",
    "        end_idx = start_idx + embedding_dim\n",
    "        grouped_features[:, i, :] = features_padded.iloc[:, start_idx:end_idx]\n",
    "\n",
    "    np.save('input_data/data_x.npy', grouped_features)\n",
    "    np.save('input_data/data_y.npy', data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(conv_dim):\n",
    "    \n",
    "    data = np.load('input_data/data_x.npy')\n",
    "    _, token_num, embedding_size = data.shape\n",
    "    label = np.load('input_data/data_y.npy')\n",
    "    num_classes = int(label.max()) + 1\n",
    "    print('num_class:', num_classes)\n",
    "    my_dataset = mydataSet(data, label)\n",
    "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "    kf_second = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "    test_ACC = []\n",
    "    test_F1 = []\n",
    "    test_PRE = []\n",
    "    for fold, (_, test_indices) in enumerate(kf.split(my_dataset, label)):\n",
    "        \n",
    "        tmp_x = my_dataset[test_indices][0]\n",
    "        tmp_y = my_dataset[test_indices][1]\n",
    "        new_test_indices, _ = next(kf_second.split(tmp_x,tmp_y), tmp_y)\n",
    "        test_indices = test_indices[new_test_indices]\n",
    "\n",
    "        transformer_model = TransformerEncoder(seq_length=token_num, token_dim=embedding_size, conv_emb_dim=conv_dim).double()\n",
    "        classification_model = MLP(input_dim=token_num, hidden_dim1 = hidden_size_1, hidden_dim2 = hidden_size_2, num_classes=num_classes).double()\n",
    "        transformer_model.to(device)\n",
    "        classification_model.to(device)\n",
    "\n",
    "        test_dataset = mydataSet(my_dataset[test_indices][0], my_dataset[test_indices][1])\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, pin_memory=True, num_workers=0)\n",
    "        test_label_counts = count_labels(test_loader)\n",
    "\n",
    "        print(f\"Test labels distribution: {test_label_counts}\")\n",
    "\n",
    "        best_model_wts = torch.load(f'ckpts/{dataset_name}/{dataset_name}_model_fold_{fold + 1}.pt')\n",
    "        transformer_model.load_state_dict(best_model_wts['transformer'])\n",
    "        classification_model.load_state_dict(best_model_wts['classification'])\n",
    "        transformer_model.eval()\n",
    "        classification_model.eval()\n",
    "        with torch.no_grad():\n",
    "            all_test_predictions = []\n",
    "            all_test_labels = []\n",
    "            for test_data_batch, test_label_batch in test_loader:\n",
    "                test_data_batch, test_label_batch = test_data_batch.to(device), test_label_batch.to(device)\n",
    "                test_transformer_output, _ = transformer_model(test_data_batch)\n",
    "                test_predictions = classification_model(test_transformer_output)\n",
    "                all_test_predictions.append(test_predictions.cpu().numpy())\n",
    "                all_test_labels.append(test_label_batch.cpu().numpy())\n",
    "            all_test_predictions = np.concatenate(all_test_predictions)\n",
    "            all_test_labels = np.concatenate(all_test_labels)\n",
    "\n",
    "            test_pred_classes = np.argmax(all_test_predictions, axis=1)\n",
    "            test_accuracy = accuracy_score(all_test_labels, test_pred_classes)\n",
    "            test_f1 = f1_score(all_test_labels, test_pred_classes, average='macro')\n",
    "            test_precision = precision_score(all_test_labels, test_pred_classes, average= 'macro')\n",
    "            test_ACC.append(test_accuracy)\n",
    "            test_F1.append(test_f1)\n",
    "            test_PRE.append(test_precision)\n",
    "\n",
    "            print(f\"Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test Precision Score: {test_precision:.4f}\\n\")\n",
    "    acc_mean, acc_std = compute_mean_std(test_ACC)\n",
    "    f1_mean, f1_std = compute_mean_std(test_F1)\n",
    "    pre_mean, pre_std = compute_mean_std(test_PRE)\n",
    "\n",
    "    print(f\"ACC: {acc_mean}±{acc_std}\")\n",
    "    print(f\"F1: {f1_mean}±{f1_std}\")\n",
    "    print(f\"Pre: {pre_mean}±{pre_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: label\n",
      "3     2525\n",
      "2     2326\n",
      "5     1077\n",
      "0      958\n",
      "4      601\n",
      "1      284\n",
      "8      255\n",
      "6      252\n",
      "11     173\n",
      "9       55\n",
      "10      25\n",
      "7       18\n",
      "12      13\n",
      "13       7\n",
      "Name: count, dtype: int64\n",
      "num_class: 14\n",
      "Test labels distribution: Counter({3: 252, 2: 233, 5: 108, 0: 96, 4: 60, 1: 28, 6: 26, 8: 25, 11: 17, 9: 6, 7: 2, 10: 2, 12: 1, 13: 1})\n",
      "Test Accuracy: 0.9848, Test F1 Score: 0.9679, Test Precision Score: 0.9623\n",
      "\n",
      "Test labels distribution: Counter({3: 252, 2: 232, 5: 108, 0: 96, 4: 60, 1: 29, 6: 25, 8: 25, 11: 17, 9: 6, 12: 2, 10: 2, 7: 2, 13: 1})\n",
      "Test Accuracy: 0.9848, Test F1 Score: 0.9890, Test Precision Score: 0.9892\n",
      "\n",
      "Test labels distribution: Counter({3: 252, 2: 232, 5: 107, 0: 96, 4: 60, 1: 29, 8: 26, 6: 25, 11: 18, 9: 6, 10: 2, 7: 2, 12: 1, 13: 1})\n",
      "Test Accuracy: 0.9848, Test F1 Score: 0.8825, Test Precision Score: 0.8866\n",
      "\n",
      "Test labels distribution: Counter({3: 252, 2: 233, 5: 108, 0: 95, 4: 61, 1: 28, 8: 26, 6: 25, 11: 17, 9: 5, 10: 3, 7: 2, 12: 1, 13: 1})\n",
      "Test Accuracy: 0.9790, Test F1 Score: 0.8789, Test Precision Score: 0.8987\n",
      "\n",
      "Test labels distribution: Counter({3: 253, 2: 233, 5: 108, 0: 95, 4: 60, 1: 28, 8: 25, 6: 25, 11: 17, 9: 6, 7: 2, 10: 2, 12: 2})\n",
      "Test Accuracy: 0.9790, Test F1 Score: 0.9643, Test Precision Score: 0.9741\n",
      "\n",
      "ACC: 0.9825±0.0032\n",
      "F1: 0.9365±0.0518\n",
      "Pre: 0.9422±0.0464\n"
     ]
    }
   ],
   "source": [
    "setup_seed(random_seed)\n",
    "data_produce(token_dim = 64)\n",
    "train(conv_dim = 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
